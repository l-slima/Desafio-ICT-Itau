Projeto: Trilha A â€“ Dados & IA - AnÃ¡lise de Custos de Nuvem AWS
ğŸ“‹ DescriÃ§Ã£o
Este projeto, desenvolvido como parte da Trilha A â€“ Dados & IA do ICT ItaÃº, cria um pipeline de ingestÃ£o e processamento de dados em Python a partir de dados pÃºblicos de custos de instÃ¢ncias AWS. Inclui um modelo de machine learning (regressÃ£o linear) para prever custos (preÃ§o on-demand Linux por hora) e anÃ¡lise exploratÃ³ria para identificar padrÃµes de uso. O objetivo Ã© suportar decisÃµes estratÃ©gicas relacionadas a custos de nuvem.

ğŸ‘¤ Autor

Nome: Lucas de Souza Lima 

ğŸ¯ Objetivos

Desenvolver um pipeline para ingerir, tratar e analisar dados de preÃ§os de instÃ¢ncias AWS.
Aplicar regressÃ£o linear para prever custos com base em recursos como vCPUs, memÃ³ria, armazenamento e GPUs.
Realizar anÃ¡lise exploratÃ³ria com visualizaÃ§Ãµes e estatÃ­sticas descritivas.
Gerar entregÃ¡veis conforme especificado (cÃ³digo comentado, notebook, CSV tratado, grÃ¡ficos).

ğŸ“‚ Estrutura do Projeto

Pipeline_Lucas_Lima.ipynb: Notebook Jupyter com o pipeline de ingestÃ£o, tratamento de dados, anÃ¡lise exploratÃ³ria e visualizaÃ§Ãµes.
regressÃ£o.ipynb: Notebook com o modelo de machine learning (regressÃ£o linear) e avaliaÃ§Ã£o.
aws_pricing_tratado.csv: Arquivo CSV contendo os dados tratados apÃ³s processamento.
images/: DiretÃ³rio com grÃ¡ficos gerados (ex.: PrevisÃ£o vs Real, ImportÃ¢ncia das Features).
README.md: Este arquivo com documentaÃ§Ã£o do projeto.

ğŸš€ Funcionalidades

IngestÃ£o e Tratamento: Carrega e trata dados ausentes do dataset AWS, salvando em aws_pricing_tratado.csv.
AnÃ¡lise ExploratÃ³ria: Gera resumos estatÃ­sticos e visualizaÃ§Ãµes (histogramas, correlaÃ§Ãµes) para recursos como vCPUs, memÃ³ria e GPUs.
Modelo de Machine Learning: Usa regressÃ£o linear para prever o preÃ§o on-demand Linux por hora, avaliado por RÂ² e RMSE.
VisualizaÃ§Ãµes: Inclui grÃ¡ficos de previsÃ£o vs real e importÃ¢ncia de features.

ğŸ“Š Resultados

Resumo EstatÃ­stico: A maioria das instÃ¢ncias tem 4-64 vCPUs, 96 GiB de memÃ³ria (mÃ¡x. 32 TiB), e poucas possuem GPUs (mÃ¡x. 8 com 1.4 TB de memÃ³ria).
Modelo de RegressÃ£o: RÂ² de 0.9303 e RMSE de 6.96, indicando alta precisÃ£o na previsÃ£o de custos.
ImportÃ¢ncia de Features: gpuCount Ã© o principal fator de custo, seguido por vCpus e memorySizeInGiB, com storageTotalSizeInGB tendo impacto mÃ­nimo.
GrÃ¡ficos: DisponÃ­veis em images/ para comparaÃ§Ã£o de previsÃµes e anÃ¡lise de correlaÃ§Ãµes.

ğŸ› ï¸ Tecnologias Utilizadas

Linguagem: Python
Bibliotecas: pandas, numpy, seaborn, matplotlib, scikit-learn
Ferramentas: Jupyter Notebook, Git

ğŸ“ InstruÃ§Ãµes de Uso

Clone o repositÃ³rio: git clone <URL_DO_REPOSITORIO>.
Instale as dependÃªncias: pip install -r requirements.txt (crie um arquivo requirements.txt com as bibliotecas listadas).
Execute pipeline_analysis.ipynb para processar os dados e gerar o CSV tratado.
Execute ml_model.ipynb para treinar o modelo e visualizar os resultados.
Verifique os grÃ¡ficos na pasta images/.

ğŸ“Œ EntregÃ¡veis

CÃ³digo-fonte comentado: DisponÃ­vel nos notebooks pipeline_analysis.ipynb e ml_model.ipynb.
Notebook: ExplicaÃ§Ãµes detalhadas e visualizaÃ§Ãµes em ambos os notebooks.
Arquivo .csv: aws_pricing_tratado.csv com dados tratados.
Prints ou grÃ¡ficos: Imagens geradas salvas em images/.

ğŸ¤ ContribuiÃ§Ãµes
ContribuiÃ§Ãµes sÃ£o bem-vindas! Abra issues ou envie pull requests para sugerir melhorias, como adiÃ§Ã£o de novos modelos (ex.: RandomForestRegressor) ou expansÃ£o do dataset.
ğŸ“– LicenÃ§a
Este projeto Ã© de uso interno do ICT ItaÃº. Para detalhes, consulte a equipe responsÃ¡vel.
