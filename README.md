Projeto: Trilha A ‚Äì Dados & IA - An√°lise de Custos de Nuvem AWS
üìã Descri√ß√£o
Este projeto, desenvolvido como parte da Trilha A ‚Äì Dados & IA do ICT Ita√∫, cria um pipeline de ingest√£o e processamento de dados em Python a partir de dados p√∫blicos de custos de inst√¢ncias AWS. Inclui um modelo de machine learning (regress√£o linear) para prever custos (pre√ßo on-demand Linux por hora) e an√°lise explorat√≥ria para identificar padr√µes de uso. O objetivo √© suportar decis√µes estrat√©gicas relacionadas a custos de nuvem.

üë§ Autor

Nome: Lucas de Souza Lima 

üéØ Objetivos

Desenvolver um pipeline para ingerir, tratar e analisar dados de pre√ßos de inst√¢ncias AWS.
Aplicar regress√£o linear para prever custos com base em recursos como vCPUs, mem√≥ria, armazenamento e GPUs.
Realizar an√°lise explorat√≥ria com visualiza√ß√µes e estat√≠sticas descritivas.
Gerar entreg√°veis conforme especificado (c√≥digo comentado, notebook, CSV tratado, gr√°ficos).

üìÇ Estrutura do Projeto

Pipeline_Lucas_Lima.ipynb: Notebook Jupyter com o pipeline de ingest√£o, tratamento de dados, an√°lise explorat√≥ria e visualiza√ß√µes.
regress√£o.ipynb: Notebook com o modelo de machine learning (regress√£o linear) e avalia√ß√£o.
aws_pricing_tratado.csv: Arquivo CSV contendo os dados tratados ap√≥s processamento.
images/: Diret√≥rio com gr√°ficos gerados (ex.: Previs√£o vs Real, Import√¢ncia das Features).
README.md: Este arquivo com documenta√ß√£o do projeto.

üöÄ Funcionalidades

Ingest√£o e Tratamento: Carrega e trata dados ausentes do dataset AWS, salvando em aws_pricing_tratado.csv.
An√°lise Explorat√≥ria: Gera resumos estat√≠sticos e visualiza√ß√µes (histogramas, correla√ß√µes) para recursos como vCPUs, mem√≥ria e GPUs.
Modelo de Machine Learning: Usa regress√£o linear para prever o pre√ßo on-demand Linux por hora, avaliado por R¬≤ e RMSE.
Visualiza√ß√µes: Inclui gr√°ficos de previs√£o vs real e import√¢ncia de features.

## üìä Resultados
### An√°lise Explorat√≥ria
- **Distribui√ß√£o de Recursos:**
  - **vCPUs:** Concentra√ß√£o em valores baixos (0-100), com uma cauda longa at√© 800 vCPUs, indicando inst√¢ncias de alta performance para HPC e big data.
  - **Mem√≥ria (memorySizeInGiB):** Maioria com at√© 5000 GiB, mas com extremos at√© 32 TiB, otimizadas para bancos de dados in-memory ou machine learning.
  - **GPUs (gpuCount):** Predomin√¢ncia de 0 GPUs, com raros casos de at√© 8 GPUs, voltados para Deep Learning e renderiza√ß√£o.
  - **Mem√≥ria Total de GPU (gpuTotalGpuMemoryInGiB):** Quase todas as inst√¢ncias t√™m 0 GiB, mas algumas alcan√ßam 1400 GiB, ideais para modelos de IA grandes.
  - **Interfaces de Rede (maxNetworkInterfaces):** Picos em 2-15 ENIs, com at√© 80 em inst√¢ncias de alta escalabilidade.
- **Resumo Estat√≠stico:**
  - **vCPUs:** M√©dia de 41.8, mediana de 16, m√°ximo de 896.
  - **Mem√≥ria:** M√©dia de 272.8 GiB, mediana de 96 GiB, m√°ximo de 32 TiB.
  - **Armazenamento:** M√©dia de 2469.4 GB, mediana de 0 GB, m√°ximo de 335 TB.
  - **GPUs:** M√©dia de 0.12, mediana de 0, m√°ximo de 8.
  - **ENIs:** M√©dia de 8.3, mediana de 8, m√°ximo de 80.
- **Insights Iniciais:** A maioria das inst√¢ncias √© b√°sica (baixa CPU, mem√≥ria moderada, sem GPU), mas h√° op√ß√µes especializadas para computa√ß√£o intensa, IA e rede escal√°vel.

### Correla√ß√£o com Pre√ßo On-Demand Linux
- **vCPUs x Pre√ßo:** Correla√ß√£o forte (0.77), destacando vCPUs como driver de custo.
- **Mem√≥ria RAM x Pre√ßo:** Correla√ß√£o muito forte (0.94), sendo o fator mais determinante.
- **Armazenamento x Pre√ßo:** Correla√ß√£o fraca (0.14), indicando custo separado (via EBS).
- **GPUs x Pre√ßo:** Correla√ß√£o fraca (0.23), com impacto dependendo da fam√≠lia da inst√¢ncia.
- **Conclus√£o da Correla√ß√£o:** O pre√ßo √© dominado por CPU e mem√≥ria, enquanto armazenamento e GPUs t√™m influ√™ncia secund√°ria.

### Modelo de Machine Learning
- **Regress√£o Linear:**
  - **Target:** Pre√ßo on-demand Linux por hora (`onDemandLinuxHr`).
  - **Features:** `vCpus`, `memorySizeInGiB`, `storageTotalSizeInGB`, `gpuCount`.
  - **Desempenho:**
    - **R¬≤:** 0.9303 (93% da variabilidade do pre√ßo explicada).
    - **RMSE:** 6.96 (erro m√©dio baixo em rela√ß√£o √† escala dos pre√ßos).
  - **Coeficientes:**
    - `gpuCount`: 1.765 (maior impacto).
    - `vCpus`: 0.0242.
    - `memorySizeInGiB`: 0.0092.
    - `storageTotalSizeInGB`: 0.000039 (m√≠nimo impacto).
- **Visualiza√ß√µes:**
  - **Previs√£o vs Real:** Gr√°fico mostra proximidade entre valores previstos e reais, com linha de perfei√ß√£o indicando boa acur√°cia.
  - **Import√¢ncia das Features:** `gpuCount` destaca-se como principal fator, seguido por `vCpus` e `memorySizeInGiB`, corroborando a an√°lise de correla√ß√£o.

### Conclus√£o Geral dos Resultados
O pipeline demonstrou que:
- A maioria das inst√¢ncias AWS atende workloads b√°sicas, mas h√° nichos para alta performance (HPC, IA, rede intensiva).
- A regress√£o linear prev√™ custos com alta precis√£o (R¬≤ de 0.93), validando CPU, mem√≥ria e GPUs como drivers principais.
- Armazenamento tem impacto negligenci√°vel no pre√ßo on-demand, alinhado com a pol√≠tica de tarifa√ß√£o da AWS.
- Os gr√°ficos e o CSV tratado (`aws_pricing_tratado.csv`) fornecem uma base s√≥lida para decis√µes estrat√©gicas no ICT Ita√∫.

üõ†Ô∏è Tecnologias Utilizadas

Linguagem: Python
Bibliotecas: pandas, numpy, seaborn, matplotlib, scikit-learn
Ferramentas: Jupyter Notebook, Git
